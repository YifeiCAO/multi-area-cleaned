{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": "%load_ext autoreload\n%autoreload 2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pdb\nfrom sklearn.model_selection import train_test_split\n\nfrom mutual_information import nnDecode"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## get direction_store and color_store"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[ pycog.rnn.RNN ] 44000 updates, best error = 0.21158187, spectral radius = 2.58479714\n Trial 2800/2800: left_right: 1, cond: 90\nThe proportion of NaN RTs is 0.000714285714286\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/michael/.virtualenvs/py2-tibi/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n  out=out, **kwargs)\n/Users/michael/.virtualenvs/py2-tibi/lib/python2.7/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
    }
   ],
   "source": "import sys\nimport subprocess\nimport numpy as np\nimport os\nimport cPickle as pkl\nimport matplotlib.pyplot as plt\nimport pdb\n# function to call unix lines\ndef call(s):\n    rv = subprocess.call(s.split())\n    if rv != 0:\n        sys.stdout.flush()\n        print(\"Something went wrong (return code {}).\".format(rv)\n              + \" We're probably out of memory.\")\n        sys.exit(1)\n\n# cd into the directory with RNNs\nos.chdir(\"/Users/michael/Documents/tibi/examples/work/data/2020-01-06_cb_3areas_ff0p1_fb0p05\")\n\n# get all files in this directory\n# from os import listdir\n# from os.path import isfile, join\n# onlyfiles = [f for f in listdir('.') if isfile(join('.', f))]\n\n# import re\n# regex = re.compile('2020-01-06_cb_3areas_ff0p1_fb0p05_lambdaw=-?\\d*\\.?\\d+([eE][-+]?\\d+)?.pkl')\n# all_files = [string for string in onlyfiles if re.match(regex, string)]\n                   \n# # add my pycog master to the path, so I can use my trial_chandr\nfrom pycog.trial_chandr import PSTH\n\n# # savepath\n# savepath = '/home2/michael/tibi/sim_output/three_rnns/'\n\n# # rnnpath \n# rnnbase = '/home2/michael/tibi/saved_rnns/three_rnns/'\n\n# # modelpath\nmodelpath = '/Users/michael/Documents/tibi/examples/models/cb_analyze.py'\n\n\nplt.close('all')\n# for (i, this_file) in enumerate(all_files):\nthis_file = '2020-01-06_cb_3areas_ff0p1_fb0p05_lr=1e-5.pkl'\n\n#     print 'On RNN {}, number {} of {}'.format(this_file, i, len(all_files))\n    # run trials to get PSTHs\nvin = 0.10**2\nvar_in = np.array(((0, 0, 0, 0), (0,0,0,0), (0,0,vin,0), (0,0,0,vin)))#0.20**2\nvar_rec = 0.05**2\n\npsth = PSTH(this_file, modelpath, rnnparams={'var_in': var_in, 'var_rec': var_rec}, num_trials=100, seed=1, threshold=0.6)\nfilename = this_file[:-4] # to remove the .pkl\n\n\npsth.sort = ['scols', 'dirs']\npsth.set_align(align='mv')\ncall('rm -f *_copy.pkl')\nbounds = [-300, 100] #used to be -500, 500\n\ntime_mv = psth.rts + [int(trial['info']['epochs']['check'][0]) for trial in psth.trials]\ntime_mv = time_mv // psth.dt\ntime_mv = time_mv.astype(int)\nrstarts = time_mv + bounds[0] // psth.dt\nrends   = time_mv + bounds[1] // psth.dt\n\nsorted_trials = psth.sort_trials()\ntrials0     = psth.trials[sorted_trials[0]['idxs']]\ntrials1     = psth.trials[sorted_trials[1]['idxs']]\ntrials2     = psth.trials[sorted_trials[2]['idxs']]\ntrials3     = psth.trials[sorted_trials[3]['idxs']]\n\nrates0 = np.array([np.mean(trial['r'][:, rstarts[idx]:rends[idx]], axis=1) for idx, trial in zip(sorted_trials[0]['idxs'], trials0)]).T\nrates1 = np.array([np.mean(trial['r'][:, rstarts[idx]:rends[idx]], axis=1) for idx, trial in zip(sorted_trials[1]['idxs'], trials1)]).T\nrates2 = np.array([np.mean(trial['r'][:, rstarts[idx]:rends[idx]], axis=1) for idx, trial in zip(sorted_trials[2]['idxs'], trials2)]).T\nrates3 = np.array([np.mean(trial['r'][:, rstarts[idx]:rends[idx]], axis=1) for idx, trial in zip(sorted_trials[3]['idxs'], trials3)]).T\n\n\nidx_nans0 = np.array([np.isnan(rate) for rate in rates0])\nidx_keep0 = np.array([not np.all(bool_across_trials) for bool_across_trials in idx_nans0.T])\nidx_nans1 = np.array([np.isnan(rate) for rate in rates1])\nidx_keep1 = np.array([not np.all(bool_across_trials) for bool_across_trials in idx_nans1.T])\nidx_nans2 = np.array([np.isnan(rate) for rate in rates2])\nidx_keep2 = np.array([not np.all(bool_across_trials) for bool_across_trials in idx_nans2.T])\nidx_nans3 = np.array([np.isnan(rate) for rate in rates3])\nidx_keep3 = np.array([not np.all(bool_across_trials) for bool_across_trials in idx_nans3.T])\n\nrates0  = rates0[:, idx_keep0]\nrates1  = rates1[:, idx_keep1]\nrates2  = rates2[:, idx_keep2]\nrates3  = rates3[:, idx_keep3] \n\n"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": "direction_store = psth.dirs\ncolor_store = psth.scols\nrates = np.array([np.mean(psth.trials[i]['r'][:, rstarts[i]:rends[i]], axis=1) for i in range(2800)])"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": "idx3 = np.hstack((np.arange(160, 161), np.arange(280, 281)))"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(2800, 300)\n"
    }
   ],
   "source": "print(rates.shape)"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(2800, 7)\n"
    }
   ],
   "source": "rates_test = rates[:, idx3]\nprint(rates_test.shape)"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": "idx1 = np.where(direction_store == 1)"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[-1 -1  1 ...  1  1 -1]\n(array([   2,    4,    5, ..., 2796, 2797, 2798]),)\n"
    }
   ],
   "source": "print(direction_store)\nprint(idx1)"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1360\n"
    }
   ],
   "source": "print(num_s1)"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(1, 1440, 100)\n"
    }
   ],
   "source": "print(s1.shape)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Analyze the mutual information"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1440\n(1440, 7)\n(2800, 7)\n(2240, 7)\n(0, 0.6944411993026733)\n(1, nan)\n(2, nan)\n(3, nan)\n(4, nan)\n(5, nan)\n(6, nan)\n(7, nan)\n(8, nan)\n(9, nan)\n(10, nan)\n(11, nan)\n(12, nan)\n(13, nan)\n(14, nan)\n(15, nan)\n(16, nan)\n(17, nan)\n(18, nan)\n(19, nan)\n(20, nan)\n(21, nan)\n(22, nan)\n(23, nan)\n(24, nan)\n(25, nan)\n(26, nan)\n(27, nan)\n(28, nan)\n(29, nan)\n(30, nan)\n(31, nan)\n(32, nan)\n(33, nan)\n(34, nan)\n(35, nan)\n(36, nan)\n(37, nan)\n(38, nan)\n(39, nan)\n(40, nan)\n(41, nan)\n(42, nan)\n(43, nan)\n(44, nan)\n(45, nan)\n(46, nan)\n(47, nan)\n(48, nan)\n(49, nan)\n(50, nan)\n(51, nan)\n(52, nan)\n(53, nan)\n(54, nan)\n(55, nan)\n(56, nan)\n(57, nan)\n(58, nan)\n(59, nan)\n(60, nan)\n(61, nan)\n(62, nan)\n(63, nan)\n(64, nan)\n(65, nan)\n(66, nan)\n(67, nan)\n(68, nan)\n(69, nan)\n(70, nan)\n(71, nan)\n(72, nan)\n(73, nan)\n(74, nan)\n(75, nan)\n(76, nan)\n(77, nan)\n(78, nan)\n(79, nan)\n(80, nan)\n(81, nan)\n(82, nan)\n(83, nan)\n(84, nan)\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-800b953ee023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# assert (false)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mmi_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnDecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# color information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmutual_information.pyc\u001b[0m in \u001b[0;36mnnDecode\u001b[0;34m(xtrain, ytrain, xtest, ytest)\u001b[0m\n",
      "\u001b[0;32m/Users/michael/.virtualenvs/py2-tibi/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michael/.virtualenvs/py2-tibi/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michael/.virtualenvs/py2-tibi/lib/python2.7/site-packages/torch/utils/data/_utils/fetch.pyc\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmutual_information.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": "# retrieve training results\n\n\n# data_save_path = '/Users/michael/Documents/GitHub/pytorch-multiarea-rnn/data_noisy_train/'\n# data_save_path = '/Users/dakshidnani/learning-dynamics/saved_models/fc_sgld/1/'\n# data_save_path = '/home/daksh/src/research/information-theory/pytorch-multiarea-rnn/saved_models/fc_sgld/1/'\n# data_save_path = '/Users/michael/Documents/GitHub/learning-dynamics/saved_models/fc_noise/2/'\n\n# h_stores = retrieve_object('h_stores.p', data_save_path)\n# direction_store = retrieve_object('direction_store.p', data_save_path)\n# color_store = retrieve_object('color_store.p', data_save_path)\n# accuracy_store = retrieve_object('accuracy_store.p', data_save_path)\n\n# mutual information through training\n# num_epochs = 100\n# subsample_epochs = 5\n\n# eval_epochs = [subsample_epochs * i for i in range(num_epochs // subsample_epochs)]  # subsample the epochs, because the sample size can be really big\n# mi_store = np.zeros((len(eval_epochs), ))\n# mi_store_color = np.zeros((len(eval_epochs), ))\n# mi_store_ctr = 0\n\n# target_fc_layer = 14\n\n# for i in eval_epochs:\nidx1 = np.where(direction_store == 1)\nidx2 = np.where(direction_store == -1)\nidx1c = np.where(color_store == 1)\nidx2c = np.where(color_store == -1)\nlayer_store = rates_test\n\n# direction information\nnum_s1 = len(idx1[0])\nnum_s2 = len(idx2[0])\nprint (num_s1)\ny = np.zeros((num_s1 + num_s2))\ny[:num_s1] = 1\ny[num_s1:] = 0\n\ns1 = layer_store[idx1, :].squeeze(axis=0)\ns2 = layer_store[idx2, :].squeeze(axis=0)\n\nx = np.concatenate((s1, s2), axis=0)\nprint(s1.shape)\nprint(x.shape)\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\nprint(X_train.shape)\n# assert (false)\nmi_store = nnDecode(X_train, y_train, X_test, y_test)\n\n# color information\nnum_s1_c = len(idx1c[0])\nnum_s2_c = len(idx2c[0])\ny = np.zeros((num_s1_c + num_s2_c))\ny[:num_s1_c] = 1\ny[num_s1_c:] = 0\ns1 = layer_store[i, idx1c, :].squeeze(axis=0)\ns2 = layer_store[i, idx2c, :].squeeze(axis=0)\nx = np.concatenate((s1, s2), axis=0)\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\nmi_store_color = nnDecode(X_train, y_train, X_test, y_test)\n\nprint(\"mi_store: \", mi_store)\nprint(\" \")\nprint(\"mi_store_color: \", mi_store_color)\n\n\n\n\n# plotting\n# plt.figure()\n# plt.plot(eval_epochs, 1 - (mi_store_color * 1.44), label='color')\n# plt.plot(eval_epochs, 1 - (mi_store * 1.44), label='direction')\n# plt.plot(eval_epochs, accuracy_store[eval_epochs], 'k--', label='accuracy')\n# plt.legend()\n# plt.ylabel('I(Z,D) and I(Z,C)')\n# plt.xlabel('epoch')\n\n# plt.savefig(os.path.join(data_save_path, 'fig.pdf'), format='pdf')\n# plt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[0.         0.14722325 0.02314536 ... 0.00903832 0.17615211 0.00237891]\n [0.00857663 0.05681213 0.15316719 ... 0.08434655 0.22745892 0.000267  ]\n [0.         0.10644542 0.08717521 ... 0.03826836 0.07065815 0.00039754]\n ...\n [0.02038996 0.01686791 0.12924762 ... 0.08490986 0.04503708 0.00391918]\n [0.         0.01142117 0.14786594 ... 0.12818342 0.11653409 0.0082683 ]\n [0.00333155 0.00484644 0.12007086 ... 0.06737408 0.07268319 0.00501282]]\n"
    }
   ],
   "source": "print(x)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "psth.sort = ['scols', 'dirs']\npsth.set_align(align='mv')\ncall('rm -f *_copy.pkl')\nbounds = [-300, 100] #used to be -500, 500\n\ntime_mv = psth.rts + [int(trial['info']['epochs']['check'][0]) for trial in psth.trials]\ntime_mv = time_mv // psth.dt\ntime_mv = time_mv.astype(int)\nrstarts = time_mv + bounds[0] // psth.dt\nrends   = time_mv + bounds[1] // psth.dt\n\nsorted_trials = psth.sort_trials()\ntrials0     = psth.trials[sorted_trials[0]['idxs']]\ntrials1     = psth.trials[sorted_trials[1]['idxs']]\ntrials2     = psth.trials[sorted_trials[2]['idxs']]\ntrials3     = psth.trials[sorted_trials[3]['idxs']]\n\nrates0 = np.array([np.mean(trial['r'][:, rstarts[idx]:rends[idx]], axis=1) for idx, trial in zip(sorted_trials[0]['idxs'], trials0)]).T\nrates1 = np.array([np.mean(trial['r'][:, rstarts[idx]:rends[idx]], axis=1) for idx, trial in zip(sorted_trials[1]['idxs'], trials1)]).T\nrates2 = np.array([np.mean(trial['r'][:, rstarts[idx]:rends[idx]], axis=1) for idx, trial in zip(sorted_trials[2]['idxs'], trials2)]).T\nrates3 = np.array([np.mean(trial['r'][:, rstarts[idx]:rends[idx]], axis=1) for idx, trial in zip(sorted_trials[3]['idxs'], trials3)]).T\n\n\nidx_nans0 = np.array([np.isnan(rate) for rate in rates0])\nidx_keep0 = np.array([not np.all(bool_across_trials) for bool_across_trials in idx_nans0.T])\nidx_nans1 = np.array([np.isnan(rate) for rate in rates1])\nidx_keep1 = np.array([not np.all(bool_across_trials) for bool_across_trials in idx_nans1.T])\nidx_nans2 = np.array([np.isnan(rate) for rate in rates2])\nidx_keep2 = np.array([not np.all(bool_across_trials) for bool_across_trials in idx_nans2.T])\nidx_nans3 = np.array([np.isnan(rate) for rate in rates3])\nidx_keep3 = np.array([not np.all(bool_across_trials) for bool_across_trials in idx_nans3.T])\n\nrates0  = rates0[:, idx_keep0]\nrates1  = rates1[:, idx_keep1]\nrates2  = rates2[:, idx_keep2]\nrates3  = rates3[:, idx_keep3]"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
